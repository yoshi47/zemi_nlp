{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import fasttext, word2vec\n",
    "from scipy.stats import spearmanr\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JWSAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.utm.inf.uec.ac.jp/JWSAN/\n",
    "jwsan_data_path = 'evaluate_dataset/jwsan-1400.csv'\n",
    "jwsan_data = pd.read_csv(jwsan_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jwsan_wv_evaluation(model, evaluation_data):\n",
    "    POS = {1: \"名詞\", 2: \"動詞\", 3: \"形容詞\"}\n",
    "    predicted_scores = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "    p_values = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "    actual_scores = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "    unknown_words = 0\n",
    "    for _, row in evaluation_data.iterrows():\n",
    "        word1 = row[\"word1\"]\n",
    "        word2 = row[\"word2\"]\n",
    "        pos = row[\"POS\"]\n",
    "        actual_score = row[\"similarity\"]\n",
    "\n",
    "        if word1 in model.wv.key_to_index and word2 in model.wv.key_to_index:\n",
    "            similarity = model.wv.similarity(word1, word2)\n",
    "        else:\n",
    "            similarity = 0.0\n",
    "            unknown_words += 1\n",
    "\n",
    "        predicted_scores[POS[pos]].append(similarity)\n",
    "        actual_scores[POS[pos]].append(actual_score)\n",
    "\n",
    "    spearman_corr = {}\n",
    "    for pos in POS.values():\n",
    "        spearman_corr[pos], p_values[pos] = spearmanr(actual_scores[pos], predicted_scores[pos])\n",
    "    spearman_corr[\"all\"], p_values[\"all\"] = spearmanr(actual_scores[\"名詞\"] + actual_scores[\"動詞\"] + actual_scores[\"形容詞\"], predicted_scores[\"名詞\"] + predicted_scores[\"動詞\"] + predicted_scores[\"形容詞\"])\n",
    "    \n",
    "    return spearman_corr, p_values, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jwsan_ft_evaluation(model, evaluation_data):\n",
    "    POS = {1: \"名詞\", 2: \"動詞\", 3: \"形容詞\"}\n",
    "    predicted_scores = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "    p_values = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "    actual_scores = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "    unknown_words = 0\n",
    "    for _, row in evaluation_data.iterrows():\n",
    "        word1 = row[\"word1\"]\n",
    "        word2 = row[\"word2\"]\n",
    "        pos = row[\"POS\"]\n",
    "        actual_score = row[\"similarity\"]\n",
    "\n",
    "        similarity = model.wv.similarity(word1, word2)\n",
    "\n",
    "        predicted_scores[POS[pos]].append(similarity)\n",
    "        actual_scores[POS[pos]].append(actual_score)\n",
    "\n",
    "    spearman_corr = {}\n",
    "    for pos in POS.values():\n",
    "        spearman_corr[pos], p_values[pos] = spearmanr(actual_scores[pos], predicted_scores[pos])\n",
    "    spearman_corr[\"all\"], p_values[\"all\"] = spearmanr(actual_scores[\"名詞\"] + actual_scores[\"動詞\"] + actual_scores[\"形容詞\"], predicted_scores[\"名詞\"] + predicted_scores[\"動詞\"] + predicted_scores[\"形容詞\"])\n",
    "    return spearman_corr, p_values, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "def preprocess(tokenizer, word):\n",
    "    word_tokens = tokenizer.tokenize(word)\n",
    "    word_tokens = [\"[CLS]\"] + word_tokens + [\"[SEP]\"]\n",
    "    word_ids = tokenizer.convert_tokens_to_ids(word_tokens)\n",
    "    word_tensor = torch.tensor([word_ids])\n",
    "    return word_tensor\n",
    "\n",
    "def embedding(model, word_tensor):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(word_tensor)\n",
    "        hidden_states = outputs[2]\n",
    "        # word_embedding = torch.stack(hidden_states[-4:]).mean(0)\n",
    "        word_embedding = hidden_states[12]\n",
    "        word_embedding = word_embedding.squeeze(0)[1]\n",
    "        # word_embedding = hidden_states[-1].squeeze(0)[1]\n",
    "    return word_embedding\n",
    "\n",
    "def jwsan_bert_evaluation(model, tokenizer, evaluation_data):\n",
    "    POS = {1: \"名詞\", 2: \"動詞\", 3: \"形容詞\"}\n",
    "    predicted_scores = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "    p_values = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "    actual_scores = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "\n",
    "    for _, row in evaluation_data.iterrows():\n",
    "        word1 = row[\"word1\"]\n",
    "        word2 = row[\"word2\"]\n",
    "        pos = row[\"POS\"]\n",
    "        actual_score = row[\"similarity\"]\n",
    "\n",
    "        word1_tensor = preprocess(tokenizer, word1)\n",
    "        word2_tensor = preprocess(tokenizer, word2)\n",
    "\n",
    "        word1_embedding = embedding(model, word1_tensor)\n",
    "        word2_embedding = embedding(model, word2_tensor)\n",
    "\n",
    "        similarity = 1 - cosine(word1_embedding, word2_embedding)\n",
    "\n",
    "        predicted_scores[POS[pos]].append(similarity)\n",
    "        actual_scores[POS[pos]].append(actual_score)\n",
    "\n",
    "    spearman_corr = {}\n",
    "    for pos in POS.values():\n",
    "        spearman_corr[pos], p_values[pos] = spearmanr(actual_scores[pos], predicted_scores[pos])\n",
    "    spearman_corr[\"all\"], p_values[\"all\"] = spearmanr(actual_scores[\"名詞\"] + actual_scores[\"動詞\"] + actual_scores[\"形容詞\"], predicted_scores[\"名詞\"] + predicted_scores[\"動詞\"] + predicted_scores[\"形容詞\"])\n",
    "    return spearman_corr, p_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# 静的にBERTのモデルの単語ベクトルを読み込む\n",
    "\n",
    "# def jwsan_bert_evaluation(model, tokenizer, evaluation_data):\n",
    "#     token_embeddings = model.get_input_embeddings().weight.cpu().detach().numpy()\n",
    "\n",
    "#     POS = {1: \"名詞\", 2: \"動詞\", 3: \"形容詞\"}\n",
    "#     predicted_scores = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "#     p_values = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "#     actual_scores = {\"名詞\": [], \"動詞\": [], \"形容詞\": []}\n",
    "\n",
    "#     for _, row in evaluation_data.iterrows():\n",
    "#         word1 = row[\"word1\"]\n",
    "#         word2 = row[\"word2\"]\n",
    "#         pos = row[\"POS\"]\n",
    "#         actual_score = row[\"similarity\"]\n",
    "\n",
    "#         word1 = tokenizer.tokenize(word1)\n",
    "#         word1_ids = tokenizer.convert_tokens_to_ids(word1)[1:]\n",
    "#         word2 = tokenizer.tokenize(word2)\n",
    "#         word2_ids = tokenizer.convert_tokens_to_ids(word2)[1:]\n",
    "\n",
    "#         word1_embedding = np.mean(token_embeddings[word1_ids], axis=0)\n",
    "#         word2_embedding = np.mean(token_embeddings[word2_ids], axis=0)\n",
    "\n",
    "#         similarity = 1 - cosine(word1_embedding, word2_embedding)\n",
    "\n",
    "#         predicted_scores[POS[pos]].append(similarity)\n",
    "#         actual_scores[POS[pos]].append(actual_score)\n",
    "\n",
    "#     spearman_corr = {}\n",
    "#     for pos in POS.values():\n",
    "#         spearman_corr[pos], p_values[pos] = spearmanr(actual_scores[pos], predicted_scores[pos])\n",
    "#     spearman_corr[\"all\"], p_values[\"all\"] = spearmanr(actual_scores[\"名詞\"] + actual_scores[\"動詞\"] + actual_scores[\"形容詞\"], predicted_scores[\"名詞\"] + predicted_scores[\"動詞\"] + predicted_scores[\"形容詞\"])\n",
    "#     return spearman_corr, p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for shunk031/JGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/shunk031/JGLUE\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 28.7k/28.7k [00:00<00:00, 62.9MB/s]\n",
      "Downloading readme: 100%|██████████| 38.6k/38.6k [00:00<00:00, 23.6MB/s]\n",
      "Downloading data: 3.16MB [00:00, 63.5MB/s]                  \n",
      "Downloading data: 372kB [00:00, 31.8MB/s]                    \n",
      "Generating train split: 12451 examples [00:00, 34788.20 examples/s]\n",
      "Generating validation split: 1457 examples [00:00, 34884.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence_pair_id', 'yjcaptions_id', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 12451\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence_pair_id', 'yjcaptions_id', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 1457\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/yahoojapan/JGLUE/blob/main/datasets/jsts-v1.1/valid-v1.1.json\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"shunk031/JGLUE\", name=\"JSTS\")\n",
    "\n",
    "jsts_data = pd.DataFrame(dataset['validation'])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jsts_data_path = 'evaluate_dataset/jsts-valid.json'\n",
    "\n",
    "# with open(jsts_data_path) as f:\n",
    "#     jsts_data = [json.loads(line) for line in f]\n",
    "\n",
    "# jsts_data = pd.DataFrame(jsts_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsts_wv_evaluation(model, evaluation_data):\n",
    "    predicted_scores = []\n",
    "    unknown_words = 0\n",
    "    for _, row in evaluation_data.iterrows():\n",
    "        sentence1 = row[\"sentence1\"]\n",
    "        sentence2 = row[\"sentence2\"]\n",
    "\n",
    "        sentence1_wakati = wakati.parse(sentence1).split()\n",
    "        sentence1_vecs = np.zeros((len(sentence1_wakati), 200))\n",
    "        for i, word in enumerate(sentence1_wakati):\n",
    "            if word in model.wv.key_to_index:\n",
    "                sentence1_vecs[i] = model.wv[word]\n",
    "            else:\n",
    "                unknown_words += 1\n",
    "\n",
    "        sentence2_wakati = wakati.parse(sentence2).split()\n",
    "        sentence2_vecs = np.zeros((len(sentence2_wakati), 200))\n",
    "        for i, word in enumerate(sentence2_wakati):\n",
    "            if word in model.wv.key_to_index:\n",
    "                sentence2_vecs[i] = model.wv[word]\n",
    "            else:\n",
    "                unknown_words += 1\n",
    "        \n",
    "        sen1 = np.mean(sentence1_vecs, axis=0)\n",
    "        sen2 = np.mean(sentence2_vecs, axis=0)\n",
    "        similarity = np.dot(sen1, sen2) / (np.linalg.norm(sen1) * np.linalg.norm(sen2))\n",
    "\n",
    "        predicted_scores.append(similarity)\n",
    "\n",
    "    actual_scores = evaluation_data[\"label\"].values\n",
    "    spearman_corr, p = spearmanr(actual_scores, predicted_scores)\n",
    "    return spearman_corr, p, unknown_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsts_ft_evaluation(model, evaluation_data):\n",
    "    predicted_scores = []\n",
    "    for _, row in evaluation_data.iterrows():\n",
    "        sentence1 = row[\"sentence1\"]\n",
    "        sentence2 = row[\"sentence2\"]\n",
    "\n",
    "        sentence1_wakati = wakati.parse(sentence1).split()\n",
    "        sentence1_vecs = np.zeros((len(sentence1_wakati), 200))\n",
    "        for i, word in enumerate(sentence1_wakati):\n",
    "            sentence1_vecs[i] = model.wv[word]\n",
    "\n",
    "\n",
    "        sentence2_wakati = wakati.parse(sentence2).split()\n",
    "        sentence2_vecs = np.zeros((len(sentence2_wakati), 200))\n",
    "        for i, word in enumerate(sentence2_wakati):\n",
    "            sentence2_vecs[i] = model.wv[word]\n",
    "        \n",
    "        sen1 = np.mean(sentence1_vecs, axis=0)\n",
    "        sen2 = np.mean(sentence2_vecs, axis=0)\n",
    "        similarity = np.dot(sen1, sen2) / (np.linalg.norm(sen1) * np.linalg.norm(sen2))\n",
    "\n",
    "        predicted_scores.append(similarity)\n",
    "\n",
    "    actual_scores = evaluation_data[\"label\"].values\n",
    "    spearman_corr, p = spearmanr(actual_scores, predicted_scores)\n",
    "    return spearman_corr, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tokenizer, sentence):\n",
    "    sentence_tokens = tokenizer.tokenize(sentence)\n",
    "    sentence_tokens = [\"[CLS]\"] + sentence_tokens + [\"[SEP]\"]\n",
    "    sentence_ids = tokenizer.convert_tokens_to_ids(sentence_tokens)\n",
    "    sentence_tensor = torch.tensor([sentence_ids])\n",
    "    return sentence_tensor\n",
    "\n",
    "def jsts_embedding(model, sentence_tensor):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(sentence_tensor)\n",
    "        hidden_states = outputs[2]\n",
    "        # sentence_embedding = torch.stack(hidden_states[-4:]).mean(0)\n",
    "        # sentence_embedding = sentence_embedding.squeeze(0)[1]\n",
    "        # sentence_embedding = hidden_states[-1].squeeze(0)[0]\n",
    "        sentence_embedding = hidden_states[-1].squeeze(0).mean(0)\n",
    "    return sentence_embedding\n",
    "\n",
    "def jsts_bert_evaluation(model, tokenizer, evaluation_data):\n",
    "    predicted_scores = []\n",
    "    for _, row in evaluation_data.iterrows():\n",
    "        sentence1 = row[\"sentence1\"]\n",
    "        sentence2 = row[\"sentence2\"]\n",
    "\n",
    "        sentence1_tensor = preprocess(tokenizer, sentence1)\n",
    "        sentence2_tensor = preprocess(tokenizer, sentence2)\n",
    "\n",
    "        sentence1_embedding = jsts_embedding(model, sentence1_tensor)\n",
    "        sentence2_embedding = jsts_embedding(model, sentence2_tensor)\n",
    "\n",
    "        similarity = 1 - cosine(sentence1_embedding, sentence2_embedding)\n",
    "\n",
    "        predicted_scores.append(similarity)\n",
    "\n",
    "    actual_scores = evaluation_data[\"label\"].values\n",
    "    spearman_corr, p = spearmanr(actual_scores, predicted_scores)\n",
    "    return spearman_corr, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルのロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForPreTraining(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertPreTrainingHeads(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=32000, bias=True)\n",
       "    )\n",
       "    (seq_relationship): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertConfig, BertForPreTraining, load_tf_weights_in_bert\n",
    "\n",
    "config = BertConfig.from_json_file('model/bert/config.json')\n",
    "bert_model = BertForPreTraining(config)\n",
    "load_tf_weights_in_bert(bert_model, config, 'model/bert/model.ckpt-1400000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a trained SentencePiece model.\n"
     ]
    }
   ],
   "source": [
    "# from bert_japanese.src import tokenization_sentencepiece as tokenization\n",
    "import tokenization_sentencepiece as tokenization\n",
    "\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    model_file='model/bert/wiki-ja.model',\n",
    "    vocab_file='model/bert/wiki-ja.vocab',\n",
    "    do_lower_case=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'こんにち', 'は']\n"
     ]
    }
   ],
   "source": [
    "a = tokenizer.tokenize('こんにちは')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 9, 30442, 11, 5]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = tokenizer.tokenize('こんにちは')\n",
    "# a.insert(0, '[CLS]')\n",
    "# a.insert(-1, '[SEP]')\n",
    "a = [\"[CLS]\"] + a + [\"[SEP]\"]\n",
    "a = tokenizer.convert_tokens_to_ids(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor([a])\n",
    "bert_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = bert_model(a)\n",
    "\n",
    "    last_hidden_states = outputs[0]\n",
    "\n",
    "    hidden_states = outputs[2]\n",
    "\n",
    "    word_embed = torch.stack(hidden_states[-4:]).sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "word_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['prediction_logits', 'seq_relationship_logits', 'hidden_states'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(outputs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len(outputs[2][12].squeeze(0)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 768)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_e = bert_model.get_input_embeddings().weight.cpu().detach().numpy()\n",
    "token_e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17818844318389893"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aa = token_e[55]\n",
    "bb = token_e[56]\n",
    "\n",
    "# cos similarity\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "1 - cosine(aa, bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'か', '細い']\n",
      "[95, 16945]\n",
      "\n",
      "['▁', '弱い']\n",
      "[8808]\n",
      "\n",
      "(768,)\n",
      "['▁', 'き', 'つい']\n",
      "[203, 10805]\n",
      "\n",
      "['▁', '甚', 'だ', 'しい']\n",
      "[13708, 314, 3456]\n",
      "\n",
      "(768,)\n",
      "['▁', 'き', 'つい']\n",
      "[203, 10805]\n",
      "\n",
      "['▁', '悲し', 'い']\n",
      "[22035, 128]\n",
      "\n",
      "(768,)\n",
      "['▁', 'けば', 'けば', 'しい']\n",
      "[14422, 14422, 3456]\n",
      "\n",
      "['▁', 'ど', 'ぎ', 'つい']\n",
      "[1362, 845, 10805]\n",
      "\n",
      "(768,)\n",
      "['▁', 'さ', 'も', 'しい']\n",
      "[338, 30, 3456]\n",
      "\n",
      "['▁', '醜', 'い']\n",
      "[25409, 128]\n",
      "\n",
      "(768,)\n",
      "['▁', 'と', 'ろ', 'い']\n",
      "[20, 1406, 128]\n",
      "\n",
      "['▁', '鈍', 'い']\n",
      "[18892, 128]\n",
      "\n",
      "(768,)\n",
      "['▁', 'や', 'ばい']\n",
      "[26, 21431]\n",
      "\n",
      "['▁', '危', 'ない']\n",
      "[14411, 278]\n",
      "\n",
      "(768,)\n",
      "['▁', '暗い']\n",
      "[15993]\n",
      "\n",
      "['▁', '湿', 'っぽい']\n",
      "[9994, 24194]\n",
      "\n",
      "(768,)\n",
      "['▁', '暗い']\n",
      "[15993]\n",
      "\n",
      "['▁', '重', '苦しい']\n",
      "[377, 24833]\n",
      "\n",
      "(768,)\n",
      "['▁', '暗い']\n",
      "[15993]\n",
      "\n",
      "['▁', '物', '悲し', 'い']\n",
      "[280, 22035, 128]\n",
      "\n",
      "(768,)\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = bert_model.get_input_embeddings().weight.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "for  idx, row in jwsan_data.iterrows():\n",
    "    if idx == 10:\n",
    "        break\n",
    "    word1 = row['word1']\n",
    "    word2 = row['word2']\n",
    "    pos = row['POS']\n",
    "    actual_score = row['similarity']\n",
    "\n",
    "    word1 = tokenizer.tokenize(word1)\n",
    "    word1_ids = tokenizer.convert_tokens_to_ids(word1)[1:]\n",
    "    print(word1)\n",
    "    print(word1_ids)\n",
    "    print()\n",
    "    word2 = tokenizer.tokenize(word2)\n",
    "    word2_ids = tokenizer.convert_tokens_to_ids(word2)[1:]\n",
    "    print(word2)\n",
    "    print(word2_ids)\n",
    "    print()\n",
    "\n",
    "    word1_embedding = np.mean(token_embeddings[word1_ids], axis=0)\n",
    "    word2_embedding = np.mean(token_embeddings[word2_ids], axis=0)\n",
    "    print(word1_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 768])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 平均\n",
    "\n",
    "torch.stack(hidden_states[-4:]).mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_states[-1].squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hidden_states[-1].squeeze(0).mean(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "outputs[2][12][0][2].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model_path = 'model/word2vec/wiki20181220_w2v.model'\n",
    "w2v_model = word2vec.Word2Vec.load(w2v_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model_path = 'model/fasttext/jawiki20181220_fasttext.model'\n",
    "ft_model = fasttext.FastText.load(ft_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "jwsan_data_path = 'evaluate_dataset/jwsan-1400.csv'\n",
    "jwsan_data = pd.read_csv(jwsan_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/datasets/load.py:1429: FutureWarning: The repository for shunk031/JGLUE contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/shunk031/JGLUE\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence_pair_id', 'yjcaptions_id', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 12451\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence_pair_id', 'yjcaptions_id', 'sentence1', 'sentence2', 'label'],\n",
      "        num_rows: 1457\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"shunk031/JGLUE\", name=\"JSTS\")\n",
    "print(dataset)\n",
    "jsts_data = pd.DataFrame(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_pair_id</th>\n",
       "      <th>yjcaptions_id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>100312_421853-104611-31624</td>\n",
       "      <td>レンガの建物の前を、乳母車を押した女性が歩いています。</td>\n",
       "      <td>厩舎で馬と女性とが寄り添っています。</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>100371-104675-104678</td>\n",
       "      <td>山の上に顔の白い牛が2頭います。</td>\n",
       "      <td>曇り空の山肌で、牛が２匹草を食んでいます。</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>100668-104946-104949</td>\n",
       "      <td>バナナを持った人が道路を通行しています。</td>\n",
       "      <td>道の上をバナナを背負った男性が歩いています。</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>100958-105177-105178</td>\n",
       "      <td>スケートボーダーが手すりを滑っています。</td>\n",
       "      <td>階段の手すりでスケートボードをする男性がいます。</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>101401-105530-105533</td>\n",
       "      <td>ダブルベッドの上で、女性が足を組み横たわっています。</td>\n",
       "      <td>ベッドの上に寝転んで、足を組んでいる人が映っています。</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_pair_id               yjcaptions_id                    sentence1  \\\n",
       "0                0  100312_421853-104611-31624  レンガの建物の前を、乳母車を押した女性が歩いています。   \n",
       "1                1        100371-104675-104678             山の上に顔の白い牛が2頭います。   \n",
       "2                2        100668-104946-104949         バナナを持った人が道路を通行しています。   \n",
       "3                3        100958-105177-105178         スケートボーダーが手すりを滑っています。   \n",
       "4                4        101401-105530-105533   ダブルベッドの上で、女性が足を組み横たわっています。   \n",
       "\n",
       "                     sentence2  label  \n",
       "0           厩舎で馬と女性とが寄り添っています。    0.0  \n",
       "1        曇り空の山肌で、牛が２匹草を食んでいます。    2.4  \n",
       "2       道の上をバナナを背負った男性が歩いています。    3.6  \n",
       "3     階段の手すりでスケートボードをする男性がいます。    4.0  \n",
       "4  ベッドの上に寝転んで、足を組んでいる人が映っています。    3.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsts_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec\n",
      "spearman_corr\n",
      "{'名詞': 0.521975358679802, '動詞': 0.4627191776866474, '形容詞': 0.3345741662764725, 'all': 0.5014307269959212}\n",
      "p_values\n",
      "{'名詞': 1.2586490589398057e-77, '動詞': 1.0359285082898006e-13, '形容詞': 0.004071720617042378, 'all': 5.191758793427666e-90}\n",
      "JWSAN spearman_corr[\"all\"]=0.5014307269959212, 5.191758793427666e-90, unknown_words=4\n",
      "JSTS spearman_corr=0.5412707509457221, 1.123398519857243e-111 unknown_words=68\n"
     ]
    }
   ],
   "source": [
    "print('word2vec')\n",
    "\n",
    "spearman_corr, p_values, unknown_words = jwsan_wv_evaluation(w2v_model, jwsan_data)\n",
    "print('spearman_corr')\n",
    "print(spearman_corr)\n",
    "print('p_values')\n",
    "print(p_values)\n",
    "# for key, p in p_values.items():\n",
    "#     print(f'{key}: {p:.4f}')\n",
    "print(f'JWSAN {spearman_corr[\"all\"]=}, {p_values[\"all\"]}, {unknown_words=}')\n",
    "\n",
    "spearman_corr, p_value, unknown_words = jsts_wv_evaluation(w2v_model, jsts_data)\n",
    "print(f'JSTS {spearman_corr=}, {p_value} {unknown_words=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "名詞: 1.259e-77\n",
      "動詞: 1.036e-13\n",
      "形容詞: 4.072e-03\n",
      "all: 5.192e-90\n",
      "1.123e-111\n"
     ]
    }
   ],
   "source": [
    "for key, p in p_values.items():\n",
    "    print(f'{key}: {p:.3e}')\n",
    "print(f'{p_value:.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext\n",
      "spearman_corr\n",
      "{'名詞': 0.5264894693586655, '動詞': 0.3115584796126147, '形容詞': 0.3119980077984522, 'all': 0.4769133175370952}\n",
      "p_values\n",
      "{'名詞': 3.5135399456097005e-79, '動詞': 1.2924265415524242e-06, '形容詞': 0.007630183136417743, 'all': 2.050039430419599e-80}\n",
      "JWSAN spearman_corr[\"all\"]=0.4769133175370952, p_values[\"all\"]=2.050039430419599e-80\n",
      "JSTS spearman_corr=0.429704866001759 p_value=1.549590212161683e-66\n"
     ]
    }
   ],
   "source": [
    "print('fasttext')\n",
    "\n",
    "spearman_corr, p_values, unknown_words = jwsan_ft_evaluation(ft_model, jwsan_data)\n",
    "\n",
    "print('spearman_corr')\n",
    "print(spearman_corr)\n",
    "print('p_values')\n",
    "print(p_values)\n",
    "print(f'JWSAN {spearman_corr[\"all\"]=}, {p_values[\"all\"]=}')\n",
    "\n",
    "spearman_corr, p_value = jsts_ft_evaluation(ft_model, jsts_data)\n",
    "print(f'JSTS {spearman_corr=} {p_value=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "名詞: 3.514e-79\n",
      "動詞: 1.292e-06\n",
      "形容詞: 7.630e-03\n",
      "all: 2.050e-80\n",
      "1.550e-66\n"
     ]
    }
   ],
   "source": [
    "for key, p in p_values.items():\n",
    "    print(f'{key}: {p:.3e}')\n",
    "print(f'{p_value:.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman_corr\n",
      "{'名詞': 0.4406580649294346, '動詞': 0.18879025293603824, '形容詞': 0.19488820566496115, 'all': 0.39198679493225075}\n",
      "p_values\n",
      "{'名詞': 2.8115695262553583e-53, '動詞': 0.003901308317660055, '形容詞': 0.10089893191352794, 'all': 1.231078845251381e-52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/usr/local/lib/python3.10/site-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "spearman_corr, p_values = jwsan_bert_evaluation(bert_model, tokenizer, jwsan_data)\n",
    "print('spearman_corr')\n",
    "print(spearman_corr)\n",
    "print('p_values')\n",
    "print(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "名詞: 2.812e-53\n",
      "動詞: 3.901e-03\n",
      "形容詞: 1.009e-01\n",
      "all: 1.231e-52\n"
     ]
    }
   ],
   "source": [
    "for key, p in p_values.items():\n",
    "    print(f'{key}: {p:.3e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spearman_corr\n",
      "0.6918930629710041\n",
      "p_values\n",
      "{'名詞': 2.8115695262553583e-53, '動詞': 0.003901308317660055, '形容詞': 0.10089893191352794, 'all': 1.231078845251381e-52}\n"
     ]
    }
   ],
   "source": [
    "spearman_corr, p_value = jsts_bert_evaluation(bert_model, tokenizer, jsts_data)\n",
    "print('spearman_corr')\n",
    "print(spearman_corr)\n",
    "print('p_values')\n",
    "print(p_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.484e-208\n"
     ]
    }
   ],
   "source": [
    "print(f'{p_value:.3e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "おまけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext min2\n",
      "spearman_corr\n",
      "{'名詞': 0.5577880945732592, '動詞': 0.26193300356131755, '形容詞': 0.24573280189537428, 'all': 0.4196253599898706}\n",
      "p_values\n",
      "{'名詞': 1.2500276027523094e-90, '動詞': 5.3717233540074785e-05, '形容詞': 0.03746700677636986, 'all': 8.062109253070062e-61}\n",
      "JWSAN spearman_corr[\"all\"]=0.4196253599898706, p_values[\"all\"]=8.062109253070062e-61\n",
      "JSTS spearman_corr=0.45533090746475025 p_value=1.7873599361056635e-75\n"
     ]
    }
   ],
   "source": [
    "ft_model_path = 'model/fasttext/min2/jawiki20181220_fasttext_min2.model'\n",
    "ft_model = fasttext.FastText.load(ft_model_path)\n",
    "\n",
    "print('fasttext min2')\n",
    "\n",
    "spearman_corr, p_values, unknown_words = jwsan_ft_evaluation(ft_model, jwsan_data)\n",
    "\n",
    "print('spearman_corr')\n",
    "print(spearman_corr)\n",
    "print('p_values')\n",
    "print(p_values)\n",
    "print(f'JWSAN {spearman_corr[\"all\"]=}, {p_values[\"all\"]=}')\n",
    "\n",
    "spearman_corr, p_value = jsts_ft_evaluation(ft_model, jsts_data)\n",
    "print(f'JSTS {spearman_corr=} {p_value=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec\n",
      "spearman_corr\n",
      "{'名詞': 0.5225075101054287, '動詞': 0.4623227533857069, '形容詞': 0.33645551281630753, 'all': 0.5015475615271434}\n",
      "p_values\n",
      "{'名詞': 8.277643031303288e-78, '動詞': 1.0939242064343544e-13, '形容詞': 0.003855946565197696, 'all': 4.6525207213432e-90}\n",
      "JWSAN spearman_corr[\"all\"]=0.5015475615271434, 4.6525207213432e-90, unknown_words=5\n",
      "JSTS spearman_corr=0.544468283981086, 3.1100765709820357e-113 unknown_words=69\n"
     ]
    }
   ],
   "source": [
    "w2v_model_path = 'more_wiki/word2vec/w2v.model'\n",
    "w2v_model = word2vec.Word2Vec.load(w2v_model_path)\n",
    "\n",
    "print('word2vec')\n",
    "\n",
    "spearman_corr, p_values, unknown_words = jwsan_wv_evaluation(w2v_model, jwsan_data)\n",
    "print('spearman_corr')\n",
    "print(spearman_corr)\n",
    "print('p_values')\n",
    "print(p_values)\n",
    "print(f'JWSAN {spearman_corr[\"all\"]=}, {p_values[\"all\"]}, {unknown_words=}')\n",
    "\n",
    "spearman_corr, p_value, unknown_words = jsts_wv_evaluation(w2v_model, jsts_data)\n",
    "print(f'JSTS {spearman_corr=}, {p_value} {unknown_words=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext\n",
      "spearman_corr\n",
      "{'名詞': 0.5267398377971378, '動詞': 0.30901512351110494, '形容詞': 0.32743469735607295, 'all': 0.47773262196515603}\n",
      "p_values\n",
      "{'名詞': 2.8764548426402363e-79, '動詞': 1.5919282296046322e-06, '形容詞': 0.0049913198149807835, 'all': 1.008149032047325e-80}\n",
      "JWSAN spearman_corr[\"all\"]=0.47773262196515603, p_values[\"all\"]=1.008149032047325e-80\n",
      "JSTS spearman_corr=0.43139756601878343 p_value=4.199539355201169e-67\n"
     ]
    }
   ],
   "source": [
    "ft_model_path = 'more_wiki/fasttext/ft.model'\n",
    "ft_model = fasttext.FastText.load(ft_model_path)\n",
    "\n",
    "print('fasttext')\n",
    "\n",
    "spearman_corr, p_values, unknown_words = jwsan_ft_evaluation(ft_model, jwsan_data)\n",
    "\n",
    "print('spearman_corr')\n",
    "print(spearman_corr)\n",
    "print('p_values')\n",
    "print(p_values)\n",
    "print(f'JWSAN {spearman_corr[\"all\"]=}, {p_values[\"all\"]=}')\n",
    "\n",
    "spearman_corr, p_value = jsts_ft_evaluation(ft_model, jsts_data)\n",
    "print(f'JSTS {spearman_corr=} {p_value=}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
